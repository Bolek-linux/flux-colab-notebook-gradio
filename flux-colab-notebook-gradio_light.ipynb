# Ten kod stworzy idealnie sformatowany plik notatnika .ipynb

notebook_content = r"""
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uruchomienie FLUX z Interfejsem Gradio (Wersja Nowoczesna i Stabilna)\\n",
    "\\n",
    "Ten notatnik uruchamia model FLUX przy użyciu **aktualnych bibliotek** preinstalowanych w Google Colab, dzięki wykorzystaniu nowoczesnej biblioteki `diffusers`. Nie wymaga on wymuszania starych wersji ani restartów sesji.\\n",
    "\\n",
    "## KROK 0: Konfiguracja Środowiska Wykonawczego\\n",
    "\\n",
    "Upewnij się, że używasz akceleratora **T4 GPU** (Runtime -> Change runtime type)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KROK 1: Instalacja i Uruchomienie Aplikacji\\n",
    "\\n",
    "Poniższa komórka zainstaluje niezbędne biblioteki, pobierze modele i uruchomi interfejs Gradio. Wszystko w jednym kroku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KOMÓRKA 1: INSTALACJA I URUCHOMIENIE\\n",
    "\\n",
    "print(\"Aktualizowanie i instalowanie niezbędnych bibliotek...\")\\n",
    "!pip install -q -U diffusers transformers accelerate bitsandbytes gradio\\n",
    "!apt -y install -qq aria2\\n",
    "\\n",
    "print(\"Pobieranie modeli...\")\\n",
    "# Uwaga: diffusers nie potrafi bezpośrednio załadować modelu 'all-in-one' z ComfyUI.\\n",
    "# Używamy oficjalnej, podzielonej wersji modelu z Hugging Face, która jest z nim równoważna.\\n",
    "CHECKPOINT_DIR = \"/content/models/checkpoints\"\\n",
    "LORA_DIR = \"/content/models/loras\"\\n",
    "!mkdir -p {CHECKPOINT_DIR}\\n",
    "!mkdir -p {LORA_DIR}\\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/flux_realism_lora.safetensors -d {LORA_DIR} -o flux_realism_lora.safetensors\\n",
    "\\n",
    "# Importy i przygotowanie środowiska\\n",
    "import torch\\n",
    "from diffusers import DiffusionPipeline\\n",
    "import gradio as gr\\n",
    "from PIL import Image\\n",
    "import random\\n",
    "\\n",
    "print(\"Ładowanie modelu FLUX (może to chwilę potrwać)...\")\\n",
    "pipe = DiffusionPipeline.from_pretrained(\\n",
    "    \"black-forest-labs/FLUX.1-dev\", \\n",
    "    torch_dtype=torch.bfloat16, \\n",
    "    # Używamy kwantyzacji, aby zmieścić się w pamięci darmowego Colaba\\n",
    "    load_in_4bit=True\\n",
    ")\\n",
    "\\n",
    "print(\"Ładowanie LoRA...\")\\n",
    "pipe.load_lora_weights(LORA_DIR, weight_name=\"flux_realism_lora.safetensors\")\\n",
    "\\n",
    "# Główna funkcja generująca\\n",
    "def generate(positive_prompt, width, height, seed, steps, guidance, lora_strength):\\n",
    "    if seed == 0:\\n",
    "        seed = random.randint(0, 2**32 - 1)\\n",
    "    print(f\"Użyte ziarno (seed): {seed}\")\\n",
    "    \\n",
    "    generator = torch.Generator(\"cuda\").manual_seed(seed)\\n",
    "    \\n",
    "    image = pipe(\\n",
    "        prompt=positive_prompt,\\n",
    "        width=width,\\n",
    "        height=height,\\n",
    "        num_inference_steps=steps,\\n",
    "        guidance_scale=guidance,\\n",
    "        generator=generator,\\n",
    "        cross_attention_kwargs={\"scale\": lora_strength} # Sposób kontrolowania siły LoRA w diffusers\\n",
    "    ).images[0]\\n",
    "    \\n",
    "    return image\\n",
    "\\n",
    "# Interfejs Gradio\\n",
    "with gr.Blocks(analytics_enabled=False) as demo:\\n",
    "    with gr.Row():\\n",
    "        with gr.Column():\\n",
    "            positive_prompt = gr.Textbox(lines=3, interactive=True, value=\"cute anime girl with massive fluffy fennec ears and a big fluffy tail blonde messy long hair blue eyes wearing a maid outfit with a long black dress with a gold leaf pattern and a white apron eating a slice of an apple pie in the kitchen of an old dark victorian mansion with a bright window and very expensive stuff everywhere\", label=\"Prompt\")\\n",
    "            width = gr.Slider(minimum=256, maximum=2048, value=1024, step=16, label=\"width\")\\n",
    "            height = gr.Slider(minimum=256, maximum=2048, value=1024, step=16, label=\"height\")\\n",
    "            seed = gr.Slider(minimum=0, maximum=2**32 - 1, value=0, step=1, label=\"seed (0=random)\")\\n",
    "            steps = gr.Slider(minimum=4, maximum=50, value=20, step=1, label=\"steps\")\\n",
    "            guidance = gr.Slider(minimum=0, maximum=20, value=3.5, step=0.5, label=\"CFG Scale / Guidance\")\\n",
    "            lora_strength = gr.Slider(minimum=0, maximum=1, value=1.0, step=0.1, label=\"LoRA Strength\")\\n",
    "            generate_button = gr.Button(\"Generate\")\\n",
    "        with gr.Column():\\n",
    "            output_image = gr.Image(label=\"Generated image\", interactive=False)\\n",
    "\\n",
    "    generate_button.click(fn=generate, inputs=[positive_prompt, width, height, seed, steps, guidance, lora_strength], outputs=output_image)\\n",
    "\\n",
    "print(\"\\nUruchamiam interfejs Gradio...\")\\n",
    "demo.queue().launch(inline=False, share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
"""

file_path = "flux_moderno_perfecto.ipynb"
with open(file_path, "w") as f:
    f.write(notebook_content)

print(f"Plik '{file_path}' został pomyślnie utworzony!")
print("Znajdziesz go w panelu plików po lewej stronie.")
