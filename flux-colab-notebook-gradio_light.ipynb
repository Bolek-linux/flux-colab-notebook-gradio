{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastyczny Notatnik FLUX z Interfejsem Gradio (Wersja Finalna)\n",
    "\n",
    "Ten notatnik przygotowuje środowisko, pobiera wszystkie 5 LoR wymaganych do odtworzenia obrazu \"Hippie Woman 1966\" z Civitai, a następnie uruchamia zaawansowany interfejs Gradio, który pozwala na pełną kontrolę nad każdą z LoR. Domyślne wartości są ustawione tak, aby od razu replikować docelowy obraz z poprawnymi siłami LoR.\n",
    "\n",
    "## KROK 0: Konfiguracja Środowiska Wykonawczego\n",
    "\n",
    "Upewnij się, że używasz akceleratora **T4 GPU** (Runtime -> Change runtime type)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KROK 1: Instalacja Zależności i Automatyczny Restart\n",
    "\n",
    "**INSTRUKCJA:**\n",
    "1.  Uruchom poniższą komórkę.\n",
    "2.  **Poczekaj**, aż zakończy swoje działanie. Sesja zostanie automatycznie przerwana (to jest normalne i oczekiwane!).\n",
    "3.  Po tym, jak sesja się zrestartuje, **ręcznie uruchom komórkę z KROKU 2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KOMÓRKA 1: INSTALACJA I AUTOMATYCZNY RESTART\n",
    "!pip install \"numpy<2\"\n",
    "!pip install torch==2.1.0 torchvision==0.16.0 xformers==0.0.22.post7 --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q torchsde einops diffusers accelerate gradio==3.50.2 python-multipart==0.0.12\n",
    "print(\"\\n✅ Instalacja zakończona. Inicjuję automatyczny restart kernela...\")\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KROK 2: Uruchomienie Aplikacji (Po Restarcie!)\n",
    "\n",
    "Tę komórkę uruchom **DOPIERO PO** restarcie sesji. Po uruchomieniu, otwórz publiczny link do interfejsu Gradio, który pojawi się na dole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KOMÓRKA 2: URUCHOMIENIE (WERSJA Z PEŁNĄ KONTROLĄ W GRADIO)\n",
    "\n",
    "%cd /content\n",
    "!git clone -b totoro4 https://github.com/camenduru/ComfyUI /content/TotoroUI\n",
    "%cd /content/TotoroUI\n",
    "!apt -y install -qq aria2\n",
    "\n",
    "print(\"Pobieranie podstawowych modeli...\")\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/flux1-dev-fp8.safetensors -d /content/TotoroUI/models/unet -o flux1-dev-fp8.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/ae.sft -d /content/TotoroUI/models/vae -o ae.sft\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/clip_l.safetensors -d /content/TotoroUI/models/clip -o clip_l.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/camenduru/FLUX.1-dev/resolve/main/t5xxl_fp8_e4m3fn.safetensors -d /content/TotoroUI/models/clip -o t5xxl_fp8_e4m3fn.safetensors\n",
    "\n",
    "print(\"Pobieranie wymaganych modeli LoRA...\")\n",
    "lora_files = {\n",
    "    \"GuyArochPhotography\": \"https://civitai.com/api/download/models/427902\",\n",
    "    \"PhoneQuality\": \"https://civitai.com/api/download/models/131881\",\n",
    "    \"EsteticHighHeels\": \"https://civitai.com/api/download/models/132839\",\n",
    "    \"FluxlissimoAURA\": \"https://civitai.com/api/download/models/428235\",\n",
    "    \"FluxlissimoCinematic\": \"https://civitai.com/api/download/models/428236\"\n",
    "}\n",
    "for name, url in lora_files.items():\n",
    "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M \"{url}\" -d /content/TotoroUI/models/loras -o {name}.safetensors\n",
    "lora_names = [name + \".safetensors\" for name in lora_files.keys()] + [\"None\"]\n",
    "\n",
    "# Importy i przygotowanie środowiska\n",
    "import random, torch, numpy as np, sys\n",
    "from PIL import Image\n",
    "sys.path.append('/content/TotoroUI')\n",
    "import nodes, gradio as gr\n",
    "from nodes import NODE_CLASS_MAPPINGS\n",
    "from totoro_extras import nodes_custom_sampler\n",
    "from totoro import model_management\n",
    "\n",
    "# Przygotowanie klas do ładowania\n",
    "LoraLoader = NODE_CLASS_MAPPINGS[\"LoraLoader\"]()\n",
    "RandomNoise = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"RandomNoise\"]()\n",
    "BasicGuider = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicGuider\"]()\n",
    "KSamplerSelect = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"KSamplerSelect\"]()\n",
    "BasicScheduler = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"BasicScheduler\"]()\n",
    "SamplerCustomAdvanced = nodes_custom_sampler.NODE_CLASS_MAPPINGS[\"SamplerCustomAdvanced\"]()\n",
    "VAEDecode = NODE_CLASS_MAPPINGS[\"VAEDecode\"]()\n",
    "EmptyLatentImage = NODE_CLASS_MAPPINGS[\"EmptyLatentImage\"]()\n",
    "UNETLoader = NODE_CLASS_MAPPINGS[\"UNETLoader\"]()\n",
    "DualCLIPLoader = NODE_CLASS_MAPPINGS[\"DualCLIPLoader\"]()\n",
    "VAELoader = NODE_CLASS_MAPPINGS[\"VAELoader\"]()\n",
    "\n",
    "print(\"Ładowanie modeli podstawowych...\")\n",
    "with torch.inference_mode():\n",
    "    unet, clip, vae = UNETLoader.load_unet(\"flux1-dev-fp8.safetensors\", \"fp8_e4m3fn\")[0], DualCLIPLoader.load_clip(\"t5xxl_fp8_e4m3fn.safetensors\", \"clip_l.safetensors\", \"flux\")[0], VAELoader.load_vae(\"ae.sft\")[0]\n",
    "print(\"Modele załadowane pomyślnie!\")\n",
    "\n",
    "def closestNumber(n, m):\n",
    "    q = int(n / m); n1 = m * q\n",
    "    if (n * m) > 0: n2 = m * (q + 1)\n",
    "    else: n2 = m * (q - 1)\n",
    "    if abs(n - n1) < abs(n - n2): return n1\n",
    "    return n2\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate(positive_prompt, width, height, seed, steps, sampler_name, scheduler, guidance, *lora_params):\n",
    "    global unet, clip\n",
    "    if seed == 0: seed = random.randint(0, 18446744073709551615)\n",
    "    print(f\"Użyte ziarno (seed): {seed}\")\n",
    "    \n",
    "    # Ładowanie LoR w pętli\n",
    "    temp_unet, temp_clip = unet, clip\n",
    "    for i in range(0, len(lora_params), 2):\n",
    "        lora_name = lora_params[i]\n",
    "        lora_strength = lora_params[i+1]\n",
    "        if lora_name != \"None\" and lora_strength > 0:\n",
    "            print(f\"Ładowanie LoRA: {lora_name} z siłą {lora_strength}\")\n",
    "            temp_unet, temp_clip = LoraLoader.load_lora(temp_unet, temp_clip, lora_name, lora_strength, lora_strength)\n",
    "    unet_lora, clip_lora = temp_unet, temp_clip\n",
    "    \n",
    "    cond, pooled = clip_lora.encode_from_tokens(clip_lora.tokenize(positive_prompt), return_pooled=True)\n",
    "    cond = [[cond, {\"pooled_output\": pooled}]]\n",
    "    noise = RandomNoise.get_noise(seed)[0]\n",
    "    guider = BasicGuider.get_guider(unet_lora, cond, guidance)[0]\n",
    "    sampler = KSamplerSelect.get_sampler(sampler_name)[0]\n",
    "    sigmas = BasicScheduler.get_sigmas(unet_lora, scheduler, steps, 1.0)[0]\n",
    "    latent_image = EmptyLatentImage.generate(closestNumber(width, 16), closestNumber(height, 16))[0]\n",
    "    sample, sample_denoised = SamplerCustomAdvanced.sample(noise, guider, sampler, sigmas, latent_image)\n",
    "    decoded = VAEDecode.decode(vae, sample)[0].detach()\n",
    "    Image.fromarray(np.array(decoded*255, dtype=np.uint8)[0]).save(\"/content/flux.png\")\n",
    "    return \"/content/flux.png\"\n",
    "\n",
    "with gr.Blocks(analytics_enabled=False) as demo:\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            positive_prompt = gr.Textbox(lines=5, interactive=True, value=\"A captivating, photorealistic image with RAW quality, cinematic grain, and eye-catching light. The scene features a 26-year-old hippie woman from 1966, radiating seductive, retro charm. She wears vibrant, psychedelic attire—a boldly patterned blouse with bell sleeves and a matching mini-skirt. Her long hair is styled in a classic '60s updo, accented with a headband, completing her look. Posing confidently in front of an orange american muscle car of 1960s, surrounded by industrial buildings on the seaport. her smile and gaze exude an irresistible allure. This image perfectly captures the essence of 1960s counterculture, blending nostalgia with timeless beauty. The shoot features vibrant colors, hyper-detailed dynamic style, with a glamorous and boudoir flair\", label=\"Prompt\")\n",
    "            with gr.Accordion(\"LoRA 1-2\", open=True):\n",
    "                lora_name_1 = gr.Dropdown(lora_names, label=\"LoRA 1 Name\", value=\"GuyArochPhotography.safetensors\")\n",
    "                lora_strength_1 = gr.Slider(minimum=0, maximum=2, value=0.7, step=0.05, label=\"LoRA 1 Strength\")\n",
    "                lora_name_2 = gr.Dropdown(lora_names, label=\"LoRA 2 Name\", value=\"PhoneQuality.safetensors\")\n",
    "                lora_strength_2 = gr.Slider(minimum=0, maximum=2, value=0.25, step=0.05, label=\"LoRA 2 Strength\")\n",
    "            with gr.Accordion(\"LoRA 3-5\", open=True):\n",
    "                lora_name_3 = gr.Dropdown(lora_names, label=\"LoRA 3 Name\", value=\"EsteticHighHeels.safetensors\")\n",
    "                lora_strength_3 = gr.Slider(minimum=0, maximum=2, value=1.0, step=0.05, label=\"LoRA 3 Strength\")\n",
    "                lora_name_4 = gr.Dropdown(lora_names, label=\"LoRA 4 Name\", value=\"FluxlissimoAURA.safetensors\")\n",
    "                lora_strength_4 = gr.Slider(minimum=0, maximum=2, value=1.5, step=0.05, label=\"LoRA 4 Strength\")\n",
    "                lora_name_5 = gr.Dropdown(lora_names, label=\"LoRA 5 Name\", value=\"FluxlissimoCinematic.safetensors\")\n",
    "                lora_strength_5 = gr.Slider(minimum=0, maximum=2, value=1.2, step=0.05, label=\"LoRA 5 Strength\")\n",
    "            generate_button = gr.Button(\"Generate\", variant=\"primary\")\n",
    "        with gr.Column(scale=1):\n",
    "            output_image = gr.Image(label=\"Generated image\", interactive=False)\n",
    "            with gr.Accordion(\"Główne Parametry\", open=True):\n",
    "                width = gr.Slider(minimum=256, maximum=2048, value=1024, step=16, label=\"width\")\n",
    "                height = gr.Slider(minimum=256, maximum=2048, value=1024, step=16, label=\"height\")\n",
    "                seed = gr.Slider(minimum=0, maximum=18446744073709551615, value=425215417, step=1, label=\"seed (0=random)\")\n",
    "            with gr.Accordion(\"Parametry Samplera\", open=True):\n",
    "                steps = gr.Slider(minimum=4, maximum=50, value=30, step=1, label=\"steps\")\n",
    "                guidance = gr.Slider(minimum=0, maximum=20, value=5.0, step=0.5, label=\"CFG Scale / Guidance\")\n",
    "                sampler_name = gr.Dropdown([\"euler\", \"heun\", \"heunpp2\", \"dpm_2\", \"lms\", \"dpmpp_2m\", \"ipndm\", \"deis\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"], label=\"sampler_name\", value=\"dpmpp_2m\")\n",
    "                scheduler = gr.Dropdown([\"normal\", \"sgm_uniform\", \"simple\", \"ddim_uniform\"], label=\"scheduler\", value=\"simple\")\n",
    "\n",
    "    all_inputs = [positive_prompt, width, height, seed, steps, sampler_name, scheduler, guidance, \n",
    "                  lora_name_1, lora_strength_1, lora_name_2, lora_strength_2, lora_name_3, lora_strength_3, \n",
    "                  lora_name_4, lora_strength_4, lora_name_5, lora_strength_5]\n",
    "    generate_button.click(fn=generate, inputs=all_inputs, outputs=output_image)\n",
    "\n",
    "print(\"\\nUruchamiam interfejs Gradio...\")\n",
    "demo.queue().launch(inline=False, share=True, debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
